{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgMdBBBIHvWC"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow import keras\n",
        "import gensim.models\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers, preprocessing\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score, ConfusionMatrixDisplay, accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "# !pip install bert-tensorflow\n",
        "from bert.tokenization import FullTokenizer\n",
        "# !pip install ekphrasis\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# !pip install emoji\n",
        "import emoji\n",
        "import re\n",
        "import random\n",
        "\n",
        "from pandas import DataFrame, read_csv\n",
        "import gc          # Garbage collector\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdcJg7q0ILbz",
        "outputId": "4a429e68-b8bc-4167-afd1-4a3142999ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import data\n",
        "df = pd.read_table(\"/content/drive/MyDrive/ADL-proj/english_dataset.tsv\", on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "knoQGKE2ITgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HziBw1JxKLY4",
        "outputId": "47dc9984-db22-47ce-9e5b-d2d109cfd228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                              tweet task_1  \\\n",
              "0  hasoc_en_1  #DhoniKeepsTheGlove | WATCH: Sports Minister K...    NOT   \n",
              "1  hasoc_en_2  @politico No. We should remember very clearly ...    HOF   \n",
              "2  hasoc_en_3  @cricketworldcup Guess who would be the winner...    NOT   \n",
              "3  hasoc_en_4  Corbyn is too politically intellectual for #Bo...    NOT   \n",
              "4  hasoc_en_5  All the best to #TeamIndia for another swimmin...    NOT   \n",
              "\n",
              "  task_2 task_3  \n",
              "0   NONE   NONE  \n",
              "1   HATE    TIN  \n",
              "2   NONE   NONE  \n",
              "3   NONE   NONE  \n",
              "4   NONE   NONE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-236346be-7f9d-477f-b701-5dc4abb29234\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>task_1</th>\n",
              "      <th>task_2</th>\n",
              "      <th>task_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hasoc_en_1</td>\n",
              "      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hasoc_en_2</td>\n",
              "      <td>@politico No. We should remember very clearly ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>HATE</td>\n",
              "      <td>TIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hasoc_en_3</td>\n",
              "      <td>@cricketworldcup Guess who would be the winner...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hasoc_en_4</td>\n",
              "      <td>Corbyn is too politically intellectual for #Bo...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hasoc_en_5</td>\n",
              "      <td>All the best to #TeamIndia for another swimmin...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-236346be-7f9d-477f-b701-5dc4abb29234')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-236346be-7f9d-477f-b701-5dc4abb29234 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-236346be-7f9d-477f-b701-5dc4abb29234');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter"
      ],
      "metadata": {
        "id": "q8ZWDlw4MQ5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_digits_emojis(s):\n",
        "    s = s.lower().strip()\n",
        "    s = emoji.demojize(s)\n",
        "    s = re.sub(r'\\d+', '', s)\n",
        "    s = re.sub(r'[^\\w\\s]', '', s)\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "def remove_urls_mentions(text):\n",
        "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n",
        "    text = text.replace(\"RT\", \"\").strip()\n",
        "    return text\n",
        "\n",
        "def replace_space(text):\n",
        "    text = text.replace(\"\\n\", \" \").strip()\n",
        "    text = re.sub(r\"\\s+\", ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "def merge_outputs(processed_text):\n",
        "    text = \"\"\n",
        "    for l in processed_text:\n",
        "        if \"</\" in l:\n",
        "            l = l.replace(\"</\", \"<\")\n",
        "\n",
        "        if l in ['<percent>', '<url>', '<', '<number>', '</allcaps>',\n",
        "                     '<money>', '<phone>', '<allcaps>', '<repeated>',  '<hashtag>',\n",
        "                      '<date>', '<time>', '<censored>', '</hashtag>', '<email>']:\n",
        "            continue\n",
        "        elif l in ['<emphasis>', '<user>', '<surprise>',  '<laugh>', '<sad>', '<annoyed>', '<happy>']:\n",
        "            if l == '<user>':\n",
        "                continue\n",
        "            else:\n",
        "                text += \" \" + l\n",
        "        else:\n",
        "            text += \" \" + replace_digits_emojis(l)\n",
        "    normalized = replace_space(text)\n",
        "    return normalized\n",
        "\n",
        "def normalize_text(input_text:str, text_preprocessor):\n",
        "    processed_text = text_preprocessor.pre_process_doc(input_text)\n",
        "    normalized_text = merge_outputs(processed_text)\n",
        "\n",
        "    return normalized_text"
      ],
      "metadata": {
        "id": "jHAqF33LaPxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_validation_set(X, y, ids):\n",
        "    validation_sample_size = int((float(len(ids)) * 0.1)/2)\n",
        "\n",
        "    X_train = {}\n",
        "    y_train = {}\n",
        "    y_train_ids = []\n",
        "    X_valid = {}\n",
        "    y_valid = {}\n",
        "    y_valid_ids = []\n",
        "\n",
        "    sampled_indexes = {0:[], 1:[]}\n",
        "    index_counter = 0\n",
        "    for label in y['output_label']:\n",
        "        if len(sampled_indexes[label]) < validation_sample_size:\n",
        "            sampled_indexes[label].append(index_counter)\n",
        "        index_counter+=1\n",
        "\n",
        "\n",
        "    for k in X:\n",
        "        data = X[k]\n",
        "\n",
        "        training_data = []\n",
        "        validation_data = []\n",
        "        index_counter = 0\n",
        "        for d in data:\n",
        "            label = y['output_label'][index_counter]\n",
        "\n",
        "            # add to validation split\n",
        "            if index_counter in sampled_indexes[label]:\n",
        "                validation_data.append(d)\n",
        "            else:\n",
        "                training_data.append(d)\n",
        "\n",
        "            index_counter +=1\n",
        "\n",
        "        X_train[k] = np.array(training_data)\n",
        "        X_valid[k] = np.array(validation_data)\n",
        "\n",
        "    for k in y:\n",
        "        data = y[k]\n",
        "\n",
        "        training_data = []\n",
        "        validation_data = []\n",
        "        index_counter = 0\n",
        "        for d in data:\n",
        "            label = y['output_label'][index_counter]\n",
        "\n",
        "            # add to validation split\n",
        "            if index_counter in sampled_indexes[label]:\n",
        "                validation_data.append(d)\n",
        "            else:\n",
        "                training_data.append(d)\n",
        "\n",
        "            index_counter +=1\n",
        "\n",
        "        y_train[k] = np.array(training_data)\n",
        "        y_valid[k] = np.array(validation_data)\n",
        "\n",
        "    index_counter = 0\n",
        "    for id in ids:\n",
        "        label = y['output_label'][index_counter]\n",
        "\n",
        "        # add to validation split\n",
        "        if index_counter in sampled_indexes[label]:\n",
        "            y_valid_ids.append(id)\n",
        "        else:\n",
        "            y_train_ids.append(id)\n",
        "\n",
        "        index_counter += 1\n",
        "\n",
        "    return X_train, y_train, y_train_ids, X_valid, y_valid, y_valid_ids"
      ],
      "metadata": {
        "id": "CZehzIw4aTSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance out Datasets : Oversampling"
      ],
      "metadata": {
        "id": "pI68IWr6ajIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_oversampling(ids, labels, text_docs):\n",
        "\n",
        "    count = {'HOF':0, 'NOT':0}\n",
        "    label_to_ids = {'HOF':[], 'NOT':[]}\n",
        "\n",
        "    c = 0\n",
        "    for l in labels:\n",
        "        count[l] +=1\n",
        "\n",
        "        id = ids[c]\n",
        "        label_to_ids[l].append(id)\n",
        "        c+=1\n",
        "\n",
        "    oversampled_ids, oversampled_labels, oversampled_text_docs = [], [], []\n",
        "\n",
        "    if count['HOF'] > count['NOT']:\n",
        "        max_label = 'HOF'\n",
        "        min_label = 'NOT'\n",
        "    else:\n",
        "        max_label = 'NOT'\n",
        "        min_label = 'HOF'\n",
        "\n",
        "\n",
        "    label_diff = count[max_label] - count[min_label]\n",
        "\n",
        "    random_ids = random.sample(label_to_ids[min_label], label_diff)\n",
        "\n",
        "    for r in random_ids:\n",
        "        id_index = ids.index(r)\n",
        "\n",
        "        oversampled_ids.append(ids[id_index])\n",
        "        oversampled_labels.append(labels[id_index])\n",
        "        oversampled_text_docs.append(text_docs[id_index])\n",
        "\n",
        "    # add the existing data\n",
        "    oversampled_ids.extend(ids)\n",
        "    oversampled_text_docs.extend(text_docs)\n",
        "    oversampled_labels.extend(labels)\n",
        "\n",
        "    return oversampled_ids, oversampled_labels, oversampled_text_docs"
      ],
      "metadata": {
        "id": "UKbEs5IRaZXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize, Padding"
      ],
      "metadata": {
        "id": "VJdgtxNHam3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tags = ['<emphasis>', '<user>', '<surprise>', '<percent>', '<url>', '<', '<number>', '</allcaps>', '<money>',\n",
        "                 '<phone>', '<allcaps>', '<repeated>', '<laugh>', '<hashtag>', '<elongated>', '<sad>', '<annoyed>',\n",
        "                 '<date>', '<time>', '<censored>', '<happy>', '</hashtag>', '<email>']\n",
        "    tokens = text.split(' ')\n",
        "    filtered_tokens = []\n",
        "\n",
        "    for t in tokens:\n",
        "        if t not in tags:\n",
        "            filtered_tokens.append(t)\n",
        "    return filtered_tokens\n",
        "\n",
        "def pad_text(max_seq_len, token_ids):\n",
        "    token_ids = token_ids[:min(len(token_ids), max_seq_len - 2)]\n",
        "    token_ids = token_ids + [0] * (max_seq_len - len(token_ids))\n",
        "    return np.array(token_ids)"
      ],
      "metadata": {
        "id": "ICrJqhMcacJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding"
      ],
      "metadata": {
        "id": "ZshEW0LGapa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_text_with_hate_words(config, data: list, hate_words: list):\n",
        "    x = list()\n",
        "    for text in data:\n",
        "\n",
        "        # tokenize\n",
        "        tokens = text.split(' ')\n",
        "        multihot_encoding_array = np.zeros(len(hate_words), dtype=int)\n",
        "\n",
        "        for t in tokens:\n",
        "            if t in hate_words:\n",
        "                index = hate_words.index(t)\n",
        "                multihot_encoding_array[index] = 1\n",
        "\n",
        "        x.append(multihot_encoding_array)\n",
        "    return np.array(x)\n",
        "\n",
        "def embed_text_with_bert(config: dict, data: list, bert_tokenizer: FullTokenizer):\n",
        "    x = list()\n",
        "\n",
        "    for text in data:\n",
        "\n",
        "        # tokenize\n",
        "        tokens = bert_tokenizer.tokenize(text)\n",
        "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "        # convert tokens into IDs by embedding the text with BERT\n",
        "        token_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
        "        # pad zeros to the token ids, if necessary\n",
        "        max_seq_len = config['tweet_text_seq_len']\n",
        "        token_ids = pad_text(max_seq_len, token_ids)\n",
        "        x.append(token_ids)\n",
        "    return np.array(x)\n",
        "\n",
        "def embed_text_with_characters(config: dict, data: list):\n",
        "    char_tokenizer = Tokenizer(lower=True, char_level=True, oov_token=\"UNKNOWN\")\n",
        "\n",
        "    alphabet = \" abcdefghijklmnopqrstuvwxyz\"\n",
        "    char_dict = {\"PADDING\": 0, \"UNKNOWN\": 1}\n",
        "    for i, char in enumerate(alphabet):\n",
        "        char_dict[char] = len(char_dict)\n",
        "\n",
        "    char_tokenizer.word_index = char_dict\n",
        "\n",
        "    x = char_tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    x_padded = pad_sequences(x, padding='post', maxlen=config['tweet_text_char_len'])\n",
        "\n",
        "    return x_padded\n"
      ],
      "metadata": {
        "id": "HW8gS8kdatmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text_docs(text_docs:list, text_preprocessor):\n",
        "    normalized_text_docs = []\n",
        "    for text in text_docs:\n",
        "        normalized_text = normalize_text(text, text_preprocessor)\n",
        "        normalized_text_docs.append(normalized_text)\n",
        "    return normalized_text_docs\n",
        "\n",
        "def encode_labels(data: list):\n",
        "    y = list()\n",
        "    label_to_index = {\"HOF\": 1, \"NOT\": 0}\n",
        "\n",
        "    for label in data:\n",
        "        y.append(label_to_index[label])\n",
        "    return np.array(y)"
      ],
      "metadata": {
        "id": "b7Tb3u2zayBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # load the Ekphrasis preprocessor\n",
        "    text_preprocessor = TextPreProcessor(\n",
        "        # terms that will be normalized\n",
        "        normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "                   'time', 'url', 'date', 'number'],\n",
        "        # terms that will be annotated\n",
        "        annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "                  'emphasis', 'censored'},\n",
        "        fix_html=True,  # fix HTML tokens\n",
        "\n",
        "        # corpus from which the word statistics are going to be used\n",
        "        # for word segmentation\n",
        "        segmenter=\"twitter\",\n",
        "\n",
        "        # corpus from which the word statistics are going to be used\n",
        "        # for spell correction\n",
        "        corrector=\"twitter\",\n",
        "\n",
        "        unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "        unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "        spell_correct_elong=False,  # spell correction for elongated words\n",
        "\n",
        "        # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "        # the tokenizer, should take as input a string and return a list of tokens\n",
        "        tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "\n",
        "        # list of dictionaries, for replacing tokens extracted from the text,\n",
        "        # with other expressions. You can pass more than one dictionaries.\n",
        "        dicts=[emoticons]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crgr23cHghiR",
        "outputId": "d45b40bd-25b2-4b7d-b3ac-0b0cb680800d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "Reading twitter - 1grams ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.iterrows():\n",
        "  row['tweet'] = replace_digits_emojis(row['tweet'])\n",
        "  row['tweet'] = remove_urls_mentions(row['tweet'])\n",
        "  row['tweet'] = replace_space(row['tweet'])\n",
        "  row['tweet'] = merge_outputs(row['tweet'])\n",
        "  row['tweet'] = normalize_text(row['tweet'], text_preprocessor)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x4e0YmBkgn45",
        "outputId": "cbc92d8d-40a2-4176-955e-e4d31c4662d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                              tweet task_1  \\\n",
              "0  hasoc_en_1  d h o n i k e e p s t h e g l o v e w a t c h ...    NOT   \n",
              "1  hasoc_en_2  p o l i t i c o n o w e s h o u l d r e m e m ...    HOF   \n",
              "2  hasoc_en_3  c r i c k e t w o r l d c u p g u e s s w h o ...    NOT   \n",
              "3  hasoc_en_4  c o r b y n i s t o o p o l i t i c a l l y i ...    NOT   \n",
              "4  hasoc_en_5  a l l t h e b e s t t o t e a m i n d i a f o ...    NOT   \n",
              "\n",
              "  task_2 task_3  \n",
              "0   NONE   NONE  \n",
              "1   HATE    TIN  \n",
              "2   NONE   NONE  \n",
              "3   NONE   NONE  \n",
              "4   NONE   NONE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb85bcfc-6d30-41cc-ace3-41940babdda9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>task_1</th>\n",
              "      <th>task_2</th>\n",
              "      <th>task_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hasoc_en_1</td>\n",
              "      <td>d h o n i k e e p s t h e g l o v e w a t c h ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hasoc_en_2</td>\n",
              "      <td>p o l i t i c o n o w e s h o u l d r e m e m ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>HATE</td>\n",
              "      <td>TIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hasoc_en_3</td>\n",
              "      <td>c r i c k e t w o r l d c u p g u e s s w h o ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hasoc_en_4</td>\n",
              "      <td>c o r b y n i s t o o p o l i t i c a l l y i ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hasoc_en_5</td>\n",
              "      <td>a l l t h e b e s t t o t e a m i n d i a f o ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb85bcfc-6d30-41cc-ace3-41940babdda9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb85bcfc-6d30-41cc-ace3-41940babdda9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb85bcfc-6d30-41cc-ace3-41940babdda9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing\n"
      ],
      "metadata": {
        "id": "VkJ3RYoGQfGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting up the data into test and training set\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = np.split(df.sample(frac=1), [int(.9*len(df))])"
      ],
      "metadata": {
        "id": "Yy63Y95KOwX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "tokenizer=''\n",
        "def preprocess_data_for_rnn(data):\n",
        "    global tokenizer\n",
        "\n",
        "    #1. Tokenize the data\n",
        "    tokenizer = Tokenizer(num_words=10000)\n",
        "    tokenizer.fit_on_texts(data['inputs'])\n",
        "    #Tensorflow’s tokenizer assigns a unique token to each distinct word. \n",
        "\n",
        "    #2. Transform/Convert text to sequence\n",
        "    train = tokenizer.texts_to_sequences(data['inputs'])\n",
        "\n",
        "    #3. Apply padding: padding is done to get all the data to the same length so as to send it to an RNN layer. \n",
        "    x_train = pad_sequences(train)\n",
        "\n",
        "    #4. encoding the outputs: target variables are also encoded to decimal values. \n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(data['tags'])\n",
        "    \n",
        "    vocabulary, input_shape, output_length=get_model_input_values(x_train, tokenizer, le)\n",
        "    \n",
        "    return x_train, y_train, vocabulary, input_shape, output_length\n",
        "\n",
        "def get_model_input_values(x_train, tokenizer, le):\n",
        "    #input length\n",
        "    input_shape = x_train.shape[0]\n",
        "    print(\"Input shape: \", input_shape)\n",
        "    #define vocabulary\n",
        "    vocabulary = len(tokenizer.word_index)\n",
        "    print(\"number of unique words in vocabulary: \",vocabulary)\n",
        "    #output length\n",
        "    output_length = le.classes_.shape[0]\n",
        "    print(\"output length: \",output_length)\n",
        "    \n",
        "    return vocabulary, input_shape, output_length"
      ],
      "metadata": {
        "id": "1S8Htu_TOxyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model: creating the model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM , Dense,GlobalMaxPooling1D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def get_rnn_model(input_shape, vocabulary):\n",
        "\n",
        "    i = Input(shape=(input_shape,))\n",
        "    x = Embedding(vocabulary+1,333)(i)\n",
        "    x = LSTM(333,return_sequences=True)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(output_length,activation=\"softmax\")(x)\n",
        "    model  = Model(i,x)\n",
        "    #compiling the model\n",
        "    model.compile( loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    return model"
      ],
      "metadata": {
        "id": "vduGtGAAOzi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_set[['tweet', 'task_1']].astype(str).rename(columns={'tweet': 'inputs', 'task_1': 'tags'})\n",
        "test_set = test_set[['tweet', 'task_1']].astype(str).rename(columns={'tweet': 'inputs', 'task_1': 'tags'})\n",
        "train_set.head()\n",
        "print(\"Total Samples to train:\", len(train_set))\n",
        "print(\"Total Samples to test:\", len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzXpKlOqO07A",
        "outputId": "b2dd0b70-5f8e-4cde-d425-e8e4536e18b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Samples to train: 5266\n",
            "Total Samples to test: 586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6O3m9bzSO2Pj",
        "outputId": "9dde78b2-25d6-40e4-c0e4-d8b4092d70dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 inputs tags\n",
              "5342  Your orange bigoted ASSHOLE boss throws babies...  HOF\n",
              "3813  .@drharshvardhan   Sur .. make central govt ru...  NOT\n",
              "5635  @realDonaldTrump @MarshaBlackburn #TrumpMustRe...  HOF\n",
              "1817  This movement is HEROIC, it is revolution agai...  NOT\n",
              "4258  @iamcardib acts like such a badass then goes a...  HOF"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3e73211-9283-4c5a-8692-ed449e7ce868\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5342</th>\n",
              "      <td>Your orange bigoted ASSHOLE boss throws babies...</td>\n",
              "      <td>HOF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3813</th>\n",
              "      <td>.@drharshvardhan   Sur .. make central govt ru...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5635</th>\n",
              "      <td>@realDonaldTrump @MarshaBlackburn #TrumpMustRe...</td>\n",
              "      <td>HOF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>This movement is HEROIC, it is revolution agai...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4258</th>\n",
              "      <td>@iamcardib acts like such a badass then goes a...</td>\n",
              "      <td>HOF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3e73211-9283-4c5a-8692-ed449e7ce868')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3e73211-9283-4c5a-8692-ed449e7ce868 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3e73211-9283-4c5a-8692-ed449e7ce868');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time x_train, y_train, vocabulary, input_shape, output_length = preprocess_data_for_rnn(train_set)\n",
        "model = get_rnn_model(input_shape, vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGZMENcTO34u",
        "outputId": "c71e4b7f-73ba-4606-d827-7e67382ad56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:  5266\n",
            "number of unique words in vocabulary:  20259\n",
            "output length:  2\n",
            "CPU times: user 352 ms, sys: 2.95 ms, total: 355 ms\n",
            "Wall time: 357 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgFS7wFoiR3H",
        "outputId": "c5f90089-386c-446b-f80b-046a21571f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5266)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 5266, 333)         6746580   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 5266, 333)         888444    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1753578)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3507158   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,142,182\n",
            "Trainable params: 11,142,182\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and validate the model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "%time history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.3, callbacks=[EarlyStopping(monitor='val_loss', patience=2, min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "H5OgJIoNiOBj",
        "outputId": "f69c7d79-9686-40e6-becb-1ec10e47a95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 5266), found shape=(None, 87)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "vx7KIrF6iacu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='validation')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "0IpEaFaqitxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentences in test_set.inputs.values:\n",
        "  #removing punctuation and converting to lowercase\n",
        "  prediction_input = [letters.lower() for letters in sentences if letters not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  print(prediction_input)\n",
        "  #texts_p.append(prediction_input)\n",
        "\n",
        "  #tokenizing and padding\n",
        "  print(prediction_input)\n",
        "  c = model.predict(prediction_input)\n",
        "  break"
      ],
      "metadata": {
        "id": "KkxyIbE8iyhs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}